# **Загрузить модель Saiga LLaMA-3 8B**

**Контекст:** Для генерации текстового рекапа нужна LLM. Saiga LLaMA-3 8B выбран как базовая модель.


**Пользовательская история:** Как система, я хочу загрузить полную версию модели Saiga LLaMA-3 8B (FP16/FP32) из Hugging Face, чтобы впоследствии на ней делать inference.


**Критерии приёмки:**
- Используется `ollama` для загрузки модели Saiga LLaMA-3 8B.
- Модель корректно инициализируется.
- На текстовом входе модель возвращает вывод без ошибок (например, несколько токенов предсказания).


**Подзадачи:**
- Найти идентификатор модели в HuggingFace (напр. `ai-forever/saiga-llama3-8b`).
- Сделать короткий тестовый запрос (например, на `print("Hello")`) и убедиться, что ответ есть.


**Ссылки/заметки:** Руководство по загрузке моделей LLaMA через Hugging Face.

**Результат:** Модуль LLM готов, модель 8B загружена и работает на тестовом запросе.
